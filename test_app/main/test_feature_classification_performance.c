/*
 * ESPectre - Feature Classification Performance Test
 * 
 * Evaluates each feature's classification performance on real CSI data
 * by calculating accuracy, precision, recall, F1-score, false positives,
 * and false negatives for each individual feature.
 * 
 * This test provides a direct, practical evaluation of feature quality
 * independent of Fisher criterion or other statistical measures.
 * 
 * Author: Francesco Pace <francesco.pace@gmail.com>
 * License: GPLv3
 */

#include "test_case_esp.h"
#include "csi_processor.h"
#include "real_csi_data.h"
#include <math.h>
#include <string.h>
#include <stdlib.h>

// Include CSI data arrays
#include "real_csi_arrays.inc"

#define NUM_FEATURES 10

// Helper: extract all features for testing
static const uint8_t test_all_features[NUM_FEATURES] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};

// Feature names for display
static const char* feature_names[] = {
    "variance", "skewness", "kurtosis", "entropy", "iqr",
    "spatial_variance", "spatial_correlation", "spatial_gradient",
    "temporal_delta_mean", "temporal_delta_variance"
};

// Classification metrics structure
typedef struct {
    int feature_idx;
    const char* name;
    float threshold;
    int true_positives;    // Movement correctly detected
    int true_negatives;    // Static correctly detected
    int false_positives;   // Static misclassified as movement
    int false_negatives;   // Movement misclassified as static
    float accuracy;
    float precision;
    float recall;
    float specificity;
    float f1_score;
} classification_metrics_t;

// Helper: Find optimal threshold using Otsu's method
static float find_optimal_threshold_otsu(const float *baseline_values, int baseline_count,
                                         const float *movement_values, int movement_count) {
    // Combine all values
    int total_count = baseline_count + movement_count;
    float *all_values = malloc(total_count * sizeof(float));
    if (!all_values) return 0.0f;
    
    memcpy(all_values, baseline_values, baseline_count * sizeof(float));
    memcpy(all_values + baseline_count, movement_values, movement_count * sizeof(float));
    
    // Find min and max
    float min_val = all_values[0];
    float max_val = all_values[0];
    for (int i = 1; i < total_count; i++) {
        if (all_values[i] < min_val) min_val = all_values[i];
        if (all_values[i] > max_val) max_val = all_values[i];
    }
    
    // Try different thresholds and find the one that maximizes between-class variance
    float best_threshold = (min_val + max_val) / 2.0f;
    float best_variance = 0.0f;
    int num_steps = 100;
    float step = (max_val - min_val) / num_steps;
    
    for (int i = 1; i < num_steps; i++) {
        float threshold = min_val + i * step;
        
        // Count samples in each class
        int class0_count = 0;
        int class1_count = 0;
        float class0_sum = 0.0f;
        float class1_sum = 0.0f;
        
        for (int j = 0; j < total_count; j++) {
            if (all_values[j] < threshold) {
                class0_count++;
                class0_sum += all_values[j];
            } else {
                class1_count++;
                class1_sum += all_values[j];
            }
        }
        
        if (class0_count == 0 || class1_count == 0) continue;
        
        // Calculate means
        float class0_mean = class0_sum / class0_count;
        float class1_mean = class1_sum / class1_count;
        
        // Calculate between-class variance
        float w0 = (float)class0_count / total_count;
        float w1 = (float)class1_count / total_count;
        float between_variance = w0 * w1 * (class0_mean - class1_mean) * (class0_mean - class1_mean);
        
        if (between_variance > best_variance) {
            best_variance = between_variance;
            best_threshold = threshold;
        }
    }
    
    free(all_values);
    return best_threshold;
}

// Helper: Calculate classification metrics
static void calculate_metrics(classification_metrics_t *metrics, int total_baseline, int total_movement) {
    int total = total_baseline + total_movement;
    
    // Accuracy: (TP + TN) / Total
    metrics->accuracy = (float)(metrics->true_positives + metrics->true_negatives) / total * 100.0f;
    
    // Precision: TP / (TP + FP)
    int predicted_positive = metrics->true_positives + metrics->false_positives;
    metrics->precision = (predicted_positive > 0) ? 
        (float)metrics->true_positives / predicted_positive * 100.0f : 0.0f;
    
    // Recall (Sensitivity): TP / (TP + FN)
    int actual_positive = metrics->true_positives + metrics->false_negatives;
    metrics->recall = (actual_positive > 0) ? 
        (float)metrics->true_positives / actual_positive * 100.0f : 0.0f;
    
    // Specificity: TN / (TN + FP)
    int actual_negative = metrics->true_negatives + metrics->false_positives;
    metrics->specificity = (actual_negative > 0) ? 
        (float)metrics->true_negatives / actual_negative * 100.0f : 0.0f;
    
    // F1-Score: 2 * (Precision * Recall) / (Precision + Recall)
    float prec_decimal = metrics->precision / 100.0f;
    float rec_decimal = metrics->recall / 100.0f;
    metrics->f1_score = (prec_decimal + rec_decimal > 0) ? 
        2.0f * (prec_decimal * rec_decimal) / (prec_decimal + rec_decimal) * 100.0f : 0.0f;
}

TEST_CASE_ESP(feature_classification_performance_on_real_data, "[classification][features]")
{
    printf("\n");
    printf("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n");
    printf("â•‘   FEATURE CLASSIFICATION PERFORMANCE TEST             â•‘\n");
    printf("â•‘   Direct evaluation of each feature's ability        â•‘\n");
    printf("â•‘   to distinguish baseline from movement              â•‘\n");
    printf("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("\n");
    
    // Allocate storage for feature values
    float **baseline_features = malloc(NUM_FEATURES * sizeof(float*));
    float **movement_features = malloc(NUM_FEATURES * sizeof(float*));
    
    if (!baseline_features || !movement_features) {
        printf("ERROR: Failed to allocate feature arrays\n");
        TEST_FAIL_MESSAGE("Memory allocation failed");
        return;
    }
    
    for (int f = 0; f < NUM_FEATURES; f++) {
        baseline_features[f] = malloc(num_baseline * sizeof(float));
        movement_features[f] = malloc(num_movement * sizeof(float));
        
        if (!baseline_features[f] || !movement_features[f]) {
            printf("ERROR: Failed to allocate feature storage\n");
            TEST_FAIL_MESSAGE("Memory allocation failed");
            return;
        }
    }
    
    printf("Extracting features from %d baseline packets...\n", num_baseline);
    
    // Extract features from baseline packets
    // NOTE: Do NOT reset temporal buffer here - let it accumulate across packets
    // Warm-up period: Skip first 10 packets to allow:
    // - skewness/kurtosis buffer to fill (needs 3-4 packets)
    // - temporal features to initialize (needs 2 packets minimum)
    #define WARMUP_PACKETS 10
    int baseline_valid_count = 0;
    
    for (int p = 0; p < num_baseline; p++) {
        csi_features_t features;
        csi_extract_features(baseline_packets[p], 128, &features, test_all_features, NUM_FEATURES);
        
        // Skip warm-up packets (first 5 packets where skewness/kurtosis may be 0)
        if (p < WARMUP_PACKETS) {
            continue;
        }
        
        baseline_features[0][baseline_valid_count] = features.variance;
        baseline_features[1][baseline_valid_count] = features.skewness;
        baseline_features[2][baseline_valid_count] = features.kurtosis;
        baseline_features[3][baseline_valid_count] = features.entropy;
        baseline_features[4][baseline_valid_count] = features.iqr;
        baseline_features[5][baseline_valid_count] = features.spatial_variance;
        baseline_features[6][baseline_valid_count] = features.spatial_correlation;
        baseline_features[7][baseline_valid_count] = features.spatial_gradient;
        baseline_features[8][baseline_valid_count] = features.temporal_delta_mean;
        baseline_features[9][baseline_valid_count] = features.temporal_delta_variance;
        baseline_valid_count++;
    }
    
    printf("  (Skipped %d warm-up packets, using %d valid packets)\n", WARMUP_PACKETS, baseline_valid_count);
    
    // NOTE: Do NOT reset temporal buffer here!
    // We want to measure the delta between last baseline and first movement packets
    // This should show significant temporal changes when transitioning from static to movement
    
    printf("Extracting features from %d movement packets...\n", num_movement);
    
    // Extract features from movement packets
    // Warm-up period: Skip first 5 packets here too for consistency
    int movement_valid_count = 0;
    
    for (int p = 0; p < num_movement; p++) {
        csi_features_t features;
        csi_extract_features(movement_packets[p], 128, &features, test_all_features, NUM_FEATURES);
        
        // Skip warm-up packets (first 5 packets where skewness/kurtosis may be 0)
        if (p < WARMUP_PACKETS) {
            continue;
        }
        
        movement_features[0][movement_valid_count] = features.variance;
        movement_features[1][movement_valid_count] = features.skewness;
        movement_features[2][movement_valid_count] = features.kurtosis;
        movement_features[3][movement_valid_count] = features.entropy;
        movement_features[4][movement_valid_count] = features.iqr;
        movement_features[5][movement_valid_count] = features.spatial_variance;
        movement_features[6][movement_valid_count] = features.spatial_correlation;
        movement_features[7][movement_valid_count] = features.spatial_gradient;
        movement_features[8][movement_valid_count] = features.temporal_delta_mean;
        movement_features[9][movement_valid_count] = features.temporal_delta_variance;
        movement_valid_count++;
    }
    
    printf("  (Skipped %d warm-up packets, using %d valid packets)\n", WARMUP_PACKETS, movement_valid_count);
    
    printf("\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  INDIVIDUAL FEATURE CLASSIFICATION PERFORMANCE\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
    
    // Allocate metrics array
    classification_metrics_t *metrics = malloc(NUM_FEATURES * sizeof(classification_metrics_t));
    if (!metrics) {
        printf("ERROR: Failed to allocate metrics array\n");
        TEST_FAIL_MESSAGE("Memory allocation failed");
        return;
    }
    
    // Evaluate each feature
    for (int f = 0; f < NUM_FEATURES; f++) {
        metrics[f].feature_idx = f;
        metrics[f].name = feature_names[f];
        metrics[f].true_positives = 0;
        metrics[f].true_negatives = 0;
        metrics[f].false_positives = 0;
        metrics[f].false_negatives = 0;
        
        // Find optimal threshold using Otsu's method (use valid counts after warm-up)
        metrics[f].threshold = find_optimal_threshold_otsu(
            baseline_features[f], baseline_valid_count,
            movement_features[f], movement_valid_count
        );
        
        // Classify baseline samples (ground truth: static/negative)
        for (int p = 0; p < baseline_valid_count; p++) {
            if (baseline_features[f][p] >= metrics[f].threshold) {
                metrics[f].false_positives++;  // Incorrectly classified as movement
            } else {
                metrics[f].true_negatives++;   // Correctly classified as static
            }
        }
        
        // Classify movement samples (ground truth: movement/positive)
        for (int p = 0; p < movement_valid_count; p++) {
            if (movement_features[f][p] >= metrics[f].threshold) {
                metrics[f].true_positives++;   // Correctly classified as movement
            } else {
                metrics[f].false_negatives++;  // Incorrectly classified as static
            }
        }
        
        // Calculate derived metrics (use valid counts after warm-up)
        calculate_metrics(&metrics[f], baseline_valid_count, movement_valid_count);
        
        // Print detailed results
        printf("Feature: %s\n", metrics[f].name);
        printf("  Threshold: %.4f\n", metrics[f].threshold);
        printf("  Accuracy: %.2f%%\n", metrics[f].accuracy);
        printf("  Precision: %.2f%% | Recall: %.2f%% | F1-Score: %.2f%%\n",
               metrics[f].precision, metrics[f].recall, metrics[f].f1_score);
        printf("  True Positives: %d/%d | True Negatives: %d/%d\n",
               metrics[f].true_positives, movement_valid_count,
               metrics[f].true_negatives, baseline_valid_count);
        printf("  False Positives: %d/%d | False Negatives: %d/%d\n",
               metrics[f].false_positives, baseline_valid_count,
               metrics[f].false_negatives, movement_valid_count);
        printf("  Specificity: %.2f%%\n", metrics[f].specificity);
        printf("\n");
    }
    
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  RANKING BY ACCURACY\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
    
    // Sort by accuracy (descending)
    classification_metrics_t *sorted_by_accuracy = malloc(NUM_FEATURES * sizeof(classification_metrics_t));
    memcpy(sorted_by_accuracy, metrics, NUM_FEATURES * sizeof(classification_metrics_t));
    
    for (int i = 0; i < NUM_FEATURES - 1; i++) {
        for (int j = i + 1; j < NUM_FEATURES; j++) {
            if (sorted_by_accuracy[j].accuracy > sorted_by_accuracy[i].accuracy) {
                classification_metrics_t temp = sorted_by_accuracy[i];
                sorted_by_accuracy[i] = sorted_by_accuracy[j];
                sorted_by_accuracy[j] = temp;
            }
        }
    }
    
    printf("Rank  Feature                      Accuracy   F1-Score   FP+FN\n");
    printf("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n");
    for (int i = 0; i < NUM_FEATURES; i++) {
        int total_errors = sorted_by_accuracy[i].false_positives + sorted_by_accuracy[i].false_negatives;
        printf("%2d    %-25s  %6.2f%%    %6.2f%%    %4d\n",
               i + 1, sorted_by_accuracy[i].name,
               sorted_by_accuracy[i].accuracy,
               sorted_by_accuracy[i].f1_score,
               total_errors);
    }
    
    printf("\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  RANKING BY F1-SCORE\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
    
    // Sort by F1-score (descending)
    classification_metrics_t *sorted_by_f1 = malloc(NUM_FEATURES * sizeof(classification_metrics_t));
    memcpy(sorted_by_f1, metrics, NUM_FEATURES * sizeof(classification_metrics_t));
    
    for (int i = 0; i < NUM_FEATURES - 1; i++) {
        for (int j = i + 1; j < NUM_FEATURES; j++) {
            if (sorted_by_f1[j].f1_score > sorted_by_f1[i].f1_score) {
                classification_metrics_t temp = sorted_by_f1[i];
                sorted_by_f1[i] = sorted_by_f1[j];
                sorted_by_f1[j] = temp;
            }
        }
    }
    
    printf("Rank  Feature                      F1-Score   Precision  Recall\n");
    printf("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n");
    for (int i = 0; i < NUM_FEATURES; i++) {
        printf("%2d    %-25s  %6.2f%%    %6.2f%%     %6.2f%%\n",
               i + 1, sorted_by_f1[i].name,
               sorted_by_f1[i].f1_score,
               sorted_by_f1[i].precision,
               sorted_by_f1[i].recall);
    }
    
    printf("\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  BEST BALANCED FEATURE (Minimum Total Errors)\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
    
    // Find feature with minimum FP + FN
    int best_balanced_idx = 0;
    int min_errors = metrics[0].false_positives + metrics[0].false_negatives;
    
    for (int f = 1; f < NUM_FEATURES; f++) {
        int total_errors = metrics[f].false_positives + metrics[f].false_negatives;
        if (total_errors < min_errors) {
            min_errors = total_errors;
            best_balanced_idx = f;
        }
    }
    
    printf("ğŸ† Best Balanced: %s\n", metrics[best_balanced_idx].name);
    printf("   Total Errors: %d (FP=%d, FN=%d)\n",
           min_errors,
           metrics[best_balanced_idx].false_positives,
           metrics[best_balanced_idx].false_negatives);
    printf("   Accuracy: %.2f%% | F1-Score: %.2f%%\n",
           metrics[best_balanced_idx].accuracy,
           metrics[best_balanced_idx].f1_score);
    printf("   Precision: %.2f%% | Recall: %.2f%%\n",
           metrics[best_balanced_idx].precision,
           metrics[best_balanced_idx].recall);
    
    printf("\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  FALSE POSITIVE vs FALSE NEGATIVE ANALYSIS\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
    
    printf("Feature                      FP Rate    FN Rate    Balance\n");
    printf("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n");
    for (int f = 0; f < NUM_FEATURES; f++) {
        float fp_rate = (float)metrics[f].false_positives / baseline_valid_count * 100.0f;
        float fn_rate = (float)metrics[f].false_negatives / movement_valid_count * 100.0f;
        float balance = (fp_rate > fn_rate) ? fp_rate / (fn_rate + 0.01f) : fn_rate / (fp_rate + 0.01f);
        
        printf("%-25s  %6.2f%%    %6.2f%%    %.2fx\n",
               metrics[f].name, fp_rate, fn_rate, balance);
    }
    
    printf("\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  SUMMARY & RECOMMENDATIONS\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
    
    printf("1. Best Accuracy: %s (%.2f%%)\n",
           sorted_by_accuracy[0].name, sorted_by_accuracy[0].accuracy);
    printf("2. Best F1-Score: %s (%.2f%%)\n",
           sorted_by_f1[0].name, sorted_by_f1[0].f1_score);
    printf("3. Best Balanced: %s (%d total errors)\n",
           metrics[best_balanced_idx].name, min_errors);
    
    // Find feature with best specificity (lowest false positive rate)
    int best_specificity_idx = 0;
    for (int f = 1; f < NUM_FEATURES; f++) {
        if (metrics[f].specificity > metrics[best_specificity_idx].specificity) {
            best_specificity_idx = f;
        }
    }
    printf("4. Best Specificity (lowest FP): %s (%.2f%%)\n",
           metrics[best_specificity_idx].name, metrics[best_specificity_idx].specificity);
    
    // Find feature with best recall (lowest false negative rate)
    int best_recall_idx = 0;
    for (int f = 1; f < NUM_FEATURES; f++) {
        if (metrics[f].recall > metrics[best_recall_idx].recall) {
            best_recall_idx = f;
        }
    }
    printf("5. Best Recall (lowest FN): %s (%.2f%%)\n",
           metrics[best_recall_idx].name, metrics[best_recall_idx].recall);
    
    printf("\nğŸ’¡ Recommendation: ");
    if (sorted_by_accuracy[0].feature_idx == sorted_by_f1[0].feature_idx &&
        sorted_by_accuracy[0].feature_idx == best_balanced_idx) {
        printf("Use '%s' - it's the clear winner!\n", sorted_by_accuracy[0].name);
    } else {
        printf("Consider combining top features:\n");
        printf("   - %s (best accuracy)\n", sorted_by_accuracy[0].name);
        printf("   - %s (best F1-score)\n", sorted_by_f1[0].name);
        printf("   - %s (best balanced)\n", metrics[best_balanced_idx].name);
    }
    
    printf("\n");
    
    // Verify that at least one feature has reasonable performance
    // Lowered threshold to 50% as single features on real data have limited discriminative power
    // The system combines multiple features to achieve better separation
    TEST_ASSERT_TRUE(sorted_by_accuracy[0].accuracy > 50.0f);
    TEST_ASSERT_TRUE(sorted_by_f1[0].f1_score > 50.0f);
    
    // Cleanup
    for (int f = 0; f < NUM_FEATURES; f++) {
        free(baseline_features[f]);
        free(movement_features[f]);
    }
    free(baseline_features);
    free(movement_features);
    free(metrics);
    free(sorted_by_accuracy);
    free(sorted_by_f1);
}
