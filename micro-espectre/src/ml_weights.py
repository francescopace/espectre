"""
Micro-ESPectre - ML Model Weights

Auto-generated neural network weights for motion detection.
Architecture: 12 -> 16 -> 8 -> 1

This file is auto-generated by 10_train_ml_model.py.
DO NOT EDIT - your changes will be overwritten!

Author: Francesco Pace <francesco.pace@gmail.com>
License: GPLv3
"""

# Feature normalization (StandardScaler)
FEATURE_MEAN = [14.152990, 2.012492, 16.994573, 7.462819, 9.531755, 5.805239, 4.765877, 2.007968, -0.270668, -1.000102, 0.000765, 0.039287]
FEATURE_SCALE = [3.379920, 1.324807, 4.297059, 5.435814, 5.226460, 6.832927, 2.613230, 0.920617, 0.600022, 0.777579, 0.046473, 3.705001]

# Layer 1: 12 -> 16 (ReLU)
W1 = [
    [-0.326002, -0.363309, 0.196931, 0.939504, -0.787091, -0.038430, -0.447660, -0.592004, 0.697325, -1.003310, -0.093751, -0.522534, 0.066063, 0.452756, -0.166290, 0.134548],
    [-0.124353, -0.119913, -0.439778, -0.372392, 0.274116, 0.488537, -0.238849, 0.202631, 0.238050, 0.227501, -0.157150, 0.395486, -0.345283, -0.036404, 0.068355, 0.577117],
    [0.146794, -0.156433, -0.524305, 0.315721, 0.342320, -0.509111, -0.614858, 0.173617, -0.056546, -0.183200, -0.053188, 0.056331, -0.282686, -0.023537, 0.579231, -0.595867],
    [0.229133, 0.180703, 0.880846, 0.021960, 0.105682, -0.997461, -0.567068, 0.376092, -0.427987, -0.892517, 0.467060, -0.735371, 0.493331, 0.733495, -0.272095, 0.213943],
    [0.565534, -0.774656, -0.849284, -0.155486, 0.141590, 0.571692, 0.174700, 0.280276, -0.176067, -0.163245, -0.769063, 0.460035, -0.229867, -0.748444, 0.391090, 0.374466],
    [-0.014422, -0.144797, 0.303683, -0.902728, 0.058946, 0.447672, 0.279914, -0.319051, 0.365062, -0.425591, 0.246063, 0.423858, -0.799338, -0.120254, 0.010862, -0.267609],
    [0.719085, -0.603052, -0.272941, -0.508641, 0.069505, -0.173578, -0.535270, 0.131079, -0.071132, 0.265696, -0.398749, 0.021214, -0.255666, -0.415005, 0.342837, 0.373906],
    [1.113976, 0.434316, -0.520114, 0.462261, 0.504340, -1.043421, 0.675659, 0.790788, -0.322348, -0.422630, -0.484995, -1.184922, -0.461832, -0.102538, 0.626285, 0.256638],
    [0.289003, -0.483287, 0.198500, 0.207425, -0.043248, -0.287061, 1.074465, -0.209226, 0.082019, 0.286876, 0.072752, -0.296352, -0.638314, 0.187342, -0.476375, 0.317011],
    [-0.361532, 0.397595, -0.550944, 0.126307, 0.186824, -0.208694, -0.781034, -0.130716, 0.142518, -0.332285, -0.285535, -0.291266, 0.351257, -0.006206, 0.245764, -0.920707],
    [0.684031, 0.144775, -0.163483, -0.216443, -0.363716, 0.350041, -0.522909, -0.329974, 0.049122, 0.356562, 0.173111, 0.164831, 0.549174, 0.469151, 0.413558, -0.272354],
    [-0.038275, -0.063576, -0.490712, 0.059869, -0.013570, -0.029959, 0.022931, 0.026821, -0.060650, 0.745484, -0.413981, 0.089034, 0.163392, -0.036207, 0.415903, -0.470489],
]
B1 = [0.187217, 0.270029, -0.141152, 0.322778, 0.334318, 0.030183, -0.002454, 0.544612, 0.114002, 0.311132, -0.269598, -0.052828, 0.482278, 0.014004, 0.693433, 0.604599]

# Layer 2: 16 -> 8 (ReLU)
W2 = [
    [-0.300415, -0.207569, 0.000967, -1.327982, 1.289638, -1.470716, 1.253453, -1.474948],
    [-0.528295, 0.037451, -0.017007, -0.304092, 0.573573, -1.174115, 0.842752, 0.229340],
    [0.395539, -0.444279, -0.332833, 1.626518, -1.528545, 0.141689, -1.731651, 1.568398],
    [-0.408203, -0.249425, -0.824824, 1.171412, -0.779172, 0.757937, -0.713591, 0.849095],
    [0.103789, -0.476526, 0.026895, -0.288018, 0.088917, -0.384532, 0.586951, -0.428491],
    [-0.258094, 0.264361, -0.262037, 0.685970, -0.664867, 1.190592, -0.634566, 0.844717],
    [-0.266144, 0.130513, 0.800553, -0.059025, -0.380133, 0.140314, 0.383187, 0.511856],
    [-0.129296, -0.003077, 0.656351, 0.117279, 0.513637, -0.509895, 1.023947, 0.256874],
    [0.329045, 0.229975, -0.748053, 0.858227, -0.198587, 0.794517, -0.759578, 0.482660],
    [0.386664, -0.353688, 0.214961, 0.685204, -1.097517, 0.947074, -0.561738, 0.306349],
    [-0.222003, 0.136273, -0.435156, 1.094723, -0.400129, 0.885801, -1.051749, 0.830769],
    [-0.363079, -0.144992, -0.752797, 0.610147, 0.213270, 0.965957, -0.510215, 0.626347],
    [-0.165869, 0.093785, -0.722399, 0.179871, 0.804511, 0.074769, 0.611769, -0.075425],
    [0.280803, -0.184501, -0.151299, 0.687626, 0.148090, 0.653455, -0.546417, 0.132764],
    [-0.337457, -0.226441, -0.931229, -0.032682, 0.505409, 0.349255, 0.105274, 0.047277],
    [0.139768, -0.381106, 0.428129, -0.263053, 0.303165, 0.052361, 1.295858, -0.649703],
]
B2 = [-0.067040, -0.062315, -0.064205, 0.047353, 0.438999, 0.083683, 0.405198, 0.030849]

# Layer 3: 8 -> 1 (Sigmoid)
W3 = [
    [0.464296],
    [0.349783],
    [1.829013],
    [-1.154013],
    [1.100728],
    [-1.624131],
    [2.212699],
    [-0.952791],
]
B3 = [0.048774]

