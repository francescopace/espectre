"""
Micro-ESPectre - ML Model Weights

Auto-generated neural network weights for motion detection.
Architecture: 12 -> 16 -> 8 -> 1

This file is auto-generated by 10_train_ml_model.py.
DO NOT EDIT - your changes will be overwritten!

Author: Francesco Pace <francesco.pace@gmail.com>
License: GPLv3
"""

# Feature normalization (StandardScaler)
FEATURE_MEAN = [14.704905, 2.304167, 18.058481, 7.970466, 0.325033, -1.760987, 9.162601, 1.995909, 0.139130, 0.754451, 0.000617, 0.031659]
FEATURE_SCALE = [3.321412, 1.402714, 4.530759, 5.006223, 0.129792, 2.526780, 13.822484, 0.872369, 0.247734, 0.847759, 0.045995, 4.068856]

# Layer 1: 12 -> 16 (ReLU)
W1 = [
    [-0.599029, 0.097546, -0.673910, 0.249432, -0.293975, -0.399008, 0.423110, 0.080972, -0.667906, 0.373713, 0.131272, -0.000140, -0.474827, -0.350668, -0.708819, 0.245620],
    [-0.233272, -0.350104, -0.158215, 0.412806, -0.105227, 0.014051, -0.571622, 0.347141, 0.188268, -0.202606, -0.474526, -0.245198, 0.297590, 0.135636, 0.024176, 0.303946],
    [0.730030, -0.215834, 0.804171, -0.065474, -0.208822, 0.109844, -0.621185, 0.076965, 0.303371, -0.648349, 0.566425, -0.165405, -0.036987, 0.317782, 0.556415, -0.176899],
    [-0.318534, 0.364900, 0.341907, -0.625345, -0.481216, -0.006509, 0.629995, -0.839711, 0.156285, 0.043549, 0.427991, 0.804063, -0.121659, 0.037187, -0.052718, -0.752075],
    [-0.048251, 0.127097, -0.435143, 0.510629, -0.351413, -0.059914, 0.086372, -0.072192, -0.176625, -0.012491, 0.307237, 0.274751, -0.182475, -0.170885, -0.440253, -0.431142],
    [-0.058825, -0.104000, -0.034607, -0.348962, 0.121349, -0.031003, -0.344141, -0.292864, 0.048189, -0.166338, 0.296584, -0.469092, 0.404495, 0.165165, 0.233393, 0.000969],
    [-0.203384, 0.154694, 0.027597, -0.374615, 0.140270, 0.278155, 0.298415, 0.054054, 0.564975, -0.417890, 0.597005, 0.364100, -0.083866, -0.049418, 0.092244, 0.433017],
    [0.470703, -0.109241, 0.054147, -0.902563, -0.409128, 0.262289, -0.339788, -1.109223, 0.499275, -0.918127, 0.373329, -0.341135, 0.449367, 0.275316, 0.266455, -0.855395],
    [0.059237, 0.071283, -0.586450, 0.480948, -0.066030, 0.419237, -0.228747, 0.218146, 0.186152, -0.072629, 0.204826, 0.030621, 0.092068, -0.258663, 0.171316, 0.147894],
    [0.086019, 0.244554, -0.000900, 0.217907, -0.407408, 0.296964, -0.332886, -0.306122, 0.444865, -0.941774, 0.194896, -0.796392, 0.275517, 0.269036, 0.208759, -0.420248],
    [0.029017, 0.039252, 0.177120, 0.030713, -0.318930, -0.258105, -0.352512, 0.218041, -0.073737, 0.230591, -0.086375, -0.114992, -0.005851, -0.219534, -0.054574, 0.131111],
    [-0.111666, -0.183899, -0.031841, 0.021583, -0.063077, -0.265732, 0.128315, -0.005633, 0.100703, -0.097953, 0.062848, -0.222197, 0.196577, 0.164613, -0.021596, 0.095195],
]
B1 = [-0.151933, -0.083186, -0.200867, -0.074796, 0.101451, -0.299342, 0.126824, 0.041388, -0.090279, 0.249983, -0.115633, 0.155359, -0.226765, -0.055878, -0.227390, 0.032001]

# Layer 2: 16 -> 8 (ReLU)
W2 = [
    [-0.274373, -0.304258, 0.478531, 0.375714, 0.581955, -0.491736, -0.402020, -0.673825],
    [-0.111592, 0.206923, 0.039234, -0.058151, -0.050573, 0.413838, 0.036658, 0.465687],
    [-0.241565, -0.254764, 0.399019, 0.756474, 0.445870, -0.120041, -0.475149, -0.400686],
    [0.429581, 0.205017, -0.555291, -0.505749, -0.678412, -0.073187, 0.375707, -0.135982],
    [0.205188, -0.535059, 0.185500, -0.164204, 0.213372, 0.743576, 0.242498, 0.421619],
    [-0.261090, -0.010987, 0.425872, 0.250422, 0.127392, -0.466227, -0.489999, -0.509936],
    [0.537302, -0.147498, -0.503205, -0.127067, -0.514469, 0.795320, 0.947525, 0.598178],
    [0.840679, 0.011675, -0.612265, -0.766019, -0.375456, 0.763849, 0.754904, 0.880281],
    [-0.014932, -0.356642, 0.221145, 0.407504, 0.429488, -0.616667, -0.253812, -0.692317],
    [0.628556, -0.005634, -0.735396, 0.110839, -0.192959, 0.655697, 0.773710, 0.519826],
    [0.100695, -0.409752, 0.014648, 0.066714, 0.149587, 0.680394, 0.090369, 0.547585],
    [0.644270, 0.028814, -0.253317, -0.418863, -0.279325, 1.044427, 0.867103, 0.315508],
    [-0.098038, 0.158979, 0.299779, 0.342380, -0.107129, -0.227862, 0.039436, -0.589488],
    [0.109362, -0.390698, -0.012227, 0.228682, 0.566301, -0.328364, -0.518444, -0.518639],
    [-0.158021, -0.389033, 0.065012, 0.392593, 0.571419, -0.471129, 0.157935, -0.024815],
    [0.812456, -0.298969, -0.674250, -0.783980, -0.105232, 0.711923, 1.100073, 0.334725],
]
B2 = [0.189446, -0.172481, 0.203246, -0.020420, -0.010029, 0.180347, 0.326470, 0.295141]

# Layer 3: 8 -> 1 (Sigmoid)
W3 = [
    [-0.968223],
    [0.480899],
    [1.294846],
    [0.852867],
    [0.799879],
    [-0.541920],
    [-0.660362],
    [-0.970041],
]
B3 = [0.216193]

