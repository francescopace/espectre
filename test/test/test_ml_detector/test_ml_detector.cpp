/*
 * ESPectre - MLDetector Unit Tests
 *
 * Tests the MLDetector class implementing BaseDetector interface.
 * Validates MLP inference accuracy against reference model outputs.
 * Test data is loaded from ml_test_data.npz (auto-generated by training script).
 *
 * Author: Francesco Pace <francesco.pace@gmail.com>
 * License: GPLv3
 */

#include <unity.h>
#include <cstdint>
#include <cstring>
#include <cmath>
#include <algorithm>
#include <vector>
#include "ml_detector.h"
#include "ml_features.h"
#include "ml_weights.h"
#include "esphome/core/log.h"
#include "cnpy.cpp"

using namespace esphome::espectre;

static const char *TAG = "test_ml_detector";

// ============================================================================
// TEST DATA (loaded from ml_test_data.npz at runtime)
// ============================================================================

#define ML_TEST_DATA_PATH "../micro-espectre/models/ml_test_data.npz"

// Sample indices to test (spread across the dataset)
static const int SAMPLE_INDICES[] = {0, 100, 500, 1000, 2000, 2500};
static const int NUM_SAMPLE_INDICES = sizeof(SAMPLE_INDICES) / sizeof(SAMPLE_INDICES[0]);

// Loaded test data
static std::vector<std::vector<float>> test_features;
static std::vector<float> test_expected;
static std::vector<int> test_labels;
static int num_test_samples = 0;
static bool data_loaded = false;

static void load_test_data() {
    if (data_loaded) return;
    
    cnpy::npz_t npz = cnpy::npz_load(ML_TEST_DATA_PATH);
    
    // Load features: shape [N, 12]
    cnpy::NpyArray& feat_arr = npz["features"];
    int total_samples = static_cast<int>(feat_arr.shape[0]);
    int num_features = static_cast<int>(feat_arr.shape[1]);
    const float* feat_data = feat_arr.data<float>();
    
    // Load expected outputs: shape [N]
    cnpy::NpyArray& exp_arr = npz["expected_outputs"];
    const float* exp_data = exp_arr.data<float>();
    
    // Load labels: shape [N]
    cnpy::NpyArray& label_arr = npz["labels"];
    const int32_t* label_data = label_arr.data<int32_t>();
    
    // Extract samples at specified indices
    for (int i = 0; i < NUM_SAMPLE_INDICES; i++) {
        int idx = SAMPLE_INDICES[i];
        if (idx >= total_samples) break;
        
        std::vector<float> features(num_features);
        for (int j = 0; j < num_features; j++) {
            features[j] = feat_data[idx * num_features + j];
        }
        test_features.push_back(features);
        test_expected.push_back(exp_data[idx]);
        test_labels.push_back(static_cast<int>(label_data[idx]));
        num_test_samples++;
    }
    
    ESP_LOGI(TAG, "Loaded %d test samples from %s (total: %d)", 
             num_test_samples, ML_TEST_DATA_PATH, total_samples);
    data_loaded = true;
}

void setUp(void) { load_test_data(); }
void tearDown(void) {}

// ============================================================================
// INITIALIZATION TESTS
// ============================================================================

void test_ml_detector_default_constructor(void) {
    MLDetector detector;
    
    TEST_ASSERT_EQUAL(DETECTOR_DEFAULT_WINDOW_SIZE, detector.get_window_size());
    TEST_ASSERT_EQUAL_FLOAT(ML_DEFAULT_THRESHOLD, detector.get_threshold());
    TEST_ASSERT_EQUAL(MotionState::IDLE, detector.get_state());
    TEST_ASSERT_EQUAL(0, detector.get_total_packets());
}

void test_ml_detector_custom_constructor(void) {
    MLDetector detector(100, 0.7f);
    
    TEST_ASSERT_EQUAL(100, detector.get_window_size());
    TEST_ASSERT_EQUAL_FLOAT(0.7f, detector.get_threshold());
}

void test_ml_detector_get_name(void) {
    MLDetector detector;
    
    TEST_ASSERT_EQUAL_STRING("ML", detector.get_name());
}

// ============================================================================
// THRESHOLD TESTS
// ============================================================================

void test_ml_detector_set_threshold_valid(void) {
    MLDetector detector;
    
    TEST_ASSERT_TRUE(detector.set_threshold(0.7f));
    TEST_ASSERT_EQUAL_FLOAT(0.7f, detector.get_threshold());
}

void test_ml_detector_set_threshold_min(void) {
    MLDetector detector;
    
    TEST_ASSERT_TRUE(detector.set_threshold(ML_MIN_THRESHOLD));
    TEST_ASSERT_EQUAL_FLOAT(ML_MIN_THRESHOLD, detector.get_threshold());
}

void test_ml_detector_set_threshold_max(void) {
    MLDetector detector;
    
    TEST_ASSERT_TRUE(detector.set_threshold(ML_MAX_THRESHOLD));
    TEST_ASSERT_EQUAL_FLOAT(ML_MAX_THRESHOLD, detector.get_threshold());
}

void test_ml_detector_set_threshold_below_min(void) {
    MLDetector detector;
    float original = detector.get_threshold();
    
    TEST_ASSERT_FALSE(detector.set_threshold(-0.1f));
    TEST_ASSERT_EQUAL_FLOAT(original, detector.get_threshold());
}

void test_ml_detector_set_threshold_above_max(void) {
    MLDetector detector;
    float original = detector.get_threshold();
    
    TEST_ASSERT_FALSE(detector.set_threshold(1.1f));
    TEST_ASSERT_EQUAL_FLOAT(original, detector.get_threshold());
}

// ============================================================================
// MLP INFERENCE TESTS
// ============================================================================

// Helper function to run MLP inference (same as MLDetector::predict)
static float run_inference(const float* features) {
    float normalized[12];
    float h1[16];
    float h2[8];
    
    // Normalize raw features using StandardScaler params
    for (int i = 0; i < 12; i++) {
        normalized[i] = (features[i] - ML_FEATURE_MEAN[i]) / ML_FEATURE_SCALE[i];
    }
    
    // Layer 1: 12 -> 16 + ReLU
    for (int j = 0; j < 16; j++) {
        h1[j] = ML_B1[j];
        for (int i = 0; i < 12; i++) {
            h1[j] += normalized[i] * ML_W1[i][j];
        }
        h1[j] = std::max(0.0f, h1[j]);
    }
    
    // Layer 2: 16 -> 8 + ReLU
    for (int j = 0; j < 8; j++) {
        h2[j] = ML_B2[j];
        for (int i = 0; i < 16; i++) {
            h2[j] += h1[i] * ML_W2[i][j];
        }
        h2[j] = std::max(0.0f, h2[j]);
    }
    
    // Layer 3: 8 -> 1 + Sigmoid
    float out = ML_B3[0];
    for (int i = 0; i < 8; i++) {
        out += h2[i] * ML_W3[i][0];
    }
    
    // Sigmoid with overflow protection
    if (out < -20.0f) return 0.0f;
    if (out > 20.0f) return 1.0f;
    return 1.0f / (1.0f + std::exp(-out));
}

void test_ml_inference_matches_reference(void) {
    const float TOLERANCE = 1e-4f;  // Allow small numerical error
    TEST_ASSERT_TRUE_MESSAGE(num_test_samples > 0, "No test data loaded");
    
    for (int i = 0; i < num_test_samples; i++) {
        float result = run_inference(test_features[i].data());
        float expected = test_expected[i];
        float error = std::abs(result - expected);
        
        ESP_LOGD(TAG, "Sample %d (idx=%d): expected=%.6f, got=%.6f, error=%.2e",
                 i, SAMPLE_INDICES[i], expected, result, error);
        
        TEST_ASSERT_FLOAT_WITHIN(TOLERANCE, expected, result);
    }
}

void test_ml_inference_output_range(void) {
    TEST_ASSERT_TRUE_MESSAGE(num_test_samples > 0, "No test data loaded");
    
    for (int i = 0; i < num_test_samples; i++) {
        float result = run_inference(test_features[i].data());
        
        TEST_ASSERT_TRUE(result >= 0.0f);
        TEST_ASSERT_TRUE(result <= 1.0f);
    }
}

void test_ml_inference_classification(void) {
    // Test that motion/idle classification is correct
    const float THRESHOLD = 0.5f;
    TEST_ASSERT_TRUE_MESSAGE(num_test_samples > 0, "No test data loaded");
    
    for (int i = 0; i < num_test_samples; i++) {
        float result = run_inference(test_features[i].data());
        float expected = test_expected[i];
        
        bool result_motion = (result > THRESHOLD);
        bool expected_motion = (expected > THRESHOLD);
        
        TEST_ASSERT_EQUAL(expected_motion, result_motion);
    }
}

// ============================================================================
// FEATURE EXTRACTION TESTS
// ============================================================================

void test_feature_extraction_basic(void) {
    float turb_buffer[50];
    float amplitudes[12] = {10.0f, 12.0f, 11.0f, 13.0f, 9.0f, 14.0f,
                            10.5f, 11.5f, 12.5f, 10.0f, 11.0f, 13.0f};
    float features[12];
    
    // Fill buffer with synthetic data
    for (int i = 0; i < 50; i++) {
        turb_buffer[i] = 10.0f + (i % 5) * 0.5f;
    }
    
    extract_ml_features(turb_buffer, 50, amplitudes, 12, features);
    
    // Verify features are reasonable
    TEST_ASSERT_TRUE(features[0] > 0);   // turb_mean > 0
    TEST_ASSERT_TRUE(features[1] >= 0);  // turb_std >= 0
    TEST_ASSERT_TRUE(features[2] >= features[3]); // turb_max >= turb_min
    TEST_ASSERT_TRUE(features[4] >= 0);  // turb_zcr >= 0
    TEST_ASSERT_TRUE(features[4] <= 1.0f); // turb_zcr <= 1
    TEST_ASSERT_TRUE(features[7] >= 0);  // entropy >= 0
    TEST_ASSERT_TRUE(features[8] >= -1.0f && features[8] <= 1.0f); // autocorr in [-1, 1]
    TEST_ASSERT_TRUE(features[9] >= 0);  // MAD >= 0
}

void test_feature_extraction_empty_buffer(void) {
    float turb_buffer[50] = {0};
    float features[12];
    
    extract_ml_features(turb_buffer, 0, nullptr, 0, features);
    
    // All features should be 0 for empty buffer
    for (int i = 0; i < 12; i++) {
        TEST_ASSERT_EQUAL_FLOAT(0.0f, features[i]);
    }
}

// ============================================================================
// ML SUBCARRIERS TESTS
// ============================================================================

void test_ml_subcarriers_count(void) {
    TEST_ASSERT_EQUAL(12, sizeof(ML_SUBCARRIERS) / sizeof(ML_SUBCARRIERS[0]));
}

void test_ml_subcarriers_range(void) {
    for (int i = 0; i < 12; i++) {
        TEST_ASSERT_TRUE(ML_SUBCARRIERS[i] >= 0);
        TEST_ASSERT_TRUE(ML_SUBCARRIERS[i] < 64);  // HT20 has 64 subcarriers
    }
}

void test_ml_subcarriers_sorted(void) {
    for (int i = 1; i < 12; i++) {
        TEST_ASSERT_TRUE(ML_SUBCARRIERS[i] > ML_SUBCARRIERS[i-1]);
    }
}

// ============================================================================
// PERFORMANCE TESTS
// ============================================================================

void test_ml_inference_performance(void) {
    const int NUM_ITERATIONS = 1000;
    
    TEST_ASSERT_TRUE_MESSAGE(num_test_samples > 0, "No test data loaded");
    
    // Warm up
    for (int i = 0; i < 10; i++) {
        run_inference(test_features[0].data());
    }
    
    // Benchmark (note: on native platform, not on actual ESP32)
    uint32_t start = 0;  // Would use micros() on ESP32
    
    for (int i = 0; i < NUM_ITERATIONS; i++) {
        run_inference(test_features[i % num_test_samples].data());
    }
    
    uint32_t elapsed = 0;  // Would calculate elapsed time
    
    // Just verify it completes without error
    ESP_LOGI(TAG, "Completed %d inference iterations", NUM_ITERATIONS);
    TEST_PASS();
}

// ============================================================================
// MAIN
// ============================================================================

int main(int argc, char **argv) {
    UNITY_BEGIN();
    
    // Initialization tests
    RUN_TEST(test_ml_detector_default_constructor);
    RUN_TEST(test_ml_detector_custom_constructor);
    RUN_TEST(test_ml_detector_get_name);
    
    // Threshold tests
    RUN_TEST(test_ml_detector_set_threshold_valid);
    RUN_TEST(test_ml_detector_set_threshold_min);
    RUN_TEST(test_ml_detector_set_threshold_max);
    RUN_TEST(test_ml_detector_set_threshold_below_min);
    RUN_TEST(test_ml_detector_set_threshold_above_max);
    
    // MLP inference tests
    RUN_TEST(test_ml_inference_matches_reference);
    RUN_TEST(test_ml_inference_output_range);
    RUN_TEST(test_ml_inference_classification);
    
    // Feature extraction tests
    RUN_TEST(test_feature_extraction_basic);
    RUN_TEST(test_feature_extraction_empty_buffer);
    
    // Subcarriers tests
    RUN_TEST(test_ml_subcarriers_count);
    RUN_TEST(test_ml_subcarriers_range);
    RUN_TEST(test_ml_subcarriers_sorted);
    
    // Performance tests
    RUN_TEST(test_ml_inference_performance);
    
    return UNITY_END();
}
